{"cells":[{"cell_type":"code","source":["%pip install -U chromadb==0.3.22 langchain==0.0.164 transformers==4.29.0 accelerate==0.19.0"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f4ca3476-8ddf-4c00-b6e7-c1cb54e05149","inputWidgets":{},"title":"Install our vector database"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run ./_resources/00-init $catalog=hive_metastore $db=dbdemos_llm"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e2bac9cb-27d9-424b-99ce-908adc4e855f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from langchain.embeddings import HuggingFaceEmbeddings\n\n# Download model from Hugging face\nhf_embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d83f10ae-9fe0-4dd0-ac7e-d0e0f225cbd8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Prepare a directory to store the document database. Any path on `/dbfs` will do.\ndbutils.widgets.dropdown(\"reset_vector_database\", \"false\", [\"false\", \"true\"], \"Recompute embeddings for chromadb\")\ngardening_vector_db_path = demo_path+\"/vector_db\"\n\n# Don't recompute the embeddings if the're already available\ncompute_embeddings = dbutils.widgets.get(\"reset_vector_database\") == \"true\" or is_folder_empty(gardening_vector_db_path)\n\nif compute_embeddings:\n  print(f\"creating folder {gardening_vector_db_path} under our blob storage (dbfs)\")\n  dbutils.fs.rm(gardening_vector_db_path, True)\n  dbutils.fs.mkdirs(gardening_vector_db_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"122b0622-4288-4ec0-9f3e-015ddd7def48","inputWidgets":{},"title":"Prepare our database storage location (in dbfs)"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Create the document database:\n- Just collect the relatively small dataset of text and form `Document`s; `langchain` can also form doc collections directly from PDFs, GDrive files, etc\n- Split long texts into manageable chunks"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ef44d0ff-7109-4864-b99c-3be7d5643d53","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from langchain.docstore.document import Document\nfrom langchain.vectorstores import Chroma\n\nall_texts = spark.table(\"default.response_dataset\").limit(500)\ngardening_vector_db_path = '/dbdemos/product/llm'\nprint(f\"Saving document embeddings under /dbfs{gardening_vector_db_path}\")\n\nif compute_embeddings: \n  # Transform our rows as langchain Documents\n  # If you want to index shorter term, use the text_short field instead\n  documents = [Document(page_content=r[\"body\"], metadata={\"source\": r[\"id\"]}) for r in all_texts.collect()]\n\n  # If your texts are long, you may need to split them. However it's best to summarize them instead as show above.\n  # text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=100)\n  # documents = text_splitter.split_documents(documents)\n\n  # Init the chroma db with the sentence-transformers/all-mpnet-base-v2 model loaded from hugging face  (hf_embed)\n  db = Chroma.from_documents(collection_name=\"gardening_docs\", documents=documents, embedding=hf_embed, persist_directory=\"/dbfs\"+gardening_vector_db_path)\n  db.similarity_search(\"dummy\") # tickle it to persist metadata (?)\n  db.persist()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d9a713e7-f7ea-4393-af23-4cb8016198c9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Set up vector database","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3805239669512148,"dataframes":["_sqldf"]}},"language":"python","widgets":{"reset_vector_database":{"nuid":"7541f93b-e762-45fa-8661-6cc741c695dc","currentValue":"false","widgetInfo":{"widgetType":"dropdown","name":"reset_vector_database","defaultValue":"false","label":"Recompute embeddings for chromadb","options":{"widgetType":"dropdown","choices":["false","true"]}}}}}},"nbformat":4,"nbformat_minor":0}
